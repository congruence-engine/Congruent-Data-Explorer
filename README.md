# The Congruent Data Explorer: Conceiving, Designing and Developing a Toolkit for Pre-Topic Modelling Data Preparation

## Short summary
A key objective of the ‘Congruence Engine’ as a whole is to understand better how machine learning methods might allow us to combine the catalogues of objects from a number of historical collections housed across the country. That task has been the focus of this collaboration, with a particular focus on the potential role of topic modelling to indicate possible ‘light’ association of items, which has extended over two phases of work. 

A first phase of work attempted to use machine-learning techniques of text analysis to topic-model across multiple data sets simultaneously and to generate hierarchised records of themes. These trials revealed that the data in its raw state is often too heterogenous, sparce and distinct from its overall context.  To address this issue this work has aimed to develop an app that can aid researchers in better understanding a dataset whilst providing a set of tools to augment, clean and otherwise contextualise the data to improve performance on downstream tasks; such as the application of clustering algorithms to vectorised data. By using new app-creation methods, it has been possible to experiment with a process of design-through-iteration: creating and reflecting on components at an early stage.

The app, called the Congruent Data Explorer, attempts to go provide a suite of tools specifically designed to enable better understand the nature of the data, optimised and with user attention focalised for this single purpose, in distinction to more generalised text wrangling tools (eg Open refine). To do this, a combination of traditional NLP tools, such as Named Entity Recognition, modern data linking methods and visualisation techniques are combined in a single application. 

The operative power of the Data Explorer is to put the analyst at the centre of the dataset, allowing them to discover new, add or otherwise edit the data, find connections and ultimately further enrich the data (e.g. adding annotations). The benefits of this work are three-fold. First, to improve the general quality of the data through the enrichment process. Second, to aid the combination of datasets across disparate sources and styles of curatorial description; third, to produce better contextualised data-points for use in downstream machine-learning tasks; such as clustering and topic-modelling.




## Research questions

- Can the results of LLM based research tasks be improved upon by providing a human-in-the-loop strategy for data exploration and manipulation prior to training/classification etc?

- How can we develop methods for combining datasets using disparate vocabularies and annotation?

- Can we add value and information to sparse information vectors through human-directed annotation and edits?


## People
**Jack Pay**


Conceptualisation, Methodology, Formal analysis, Visualisation, Writing – original draft

**Alex Butterworth**


Conceptualisation, Methodology, Project administration, Supervision, Writing – original draft

**Andrew Robinson**


Resource

**Daniel Belteki**


Investigation

**Tasha Kitcher** 


Investigation


## Data sources


Multiple proprietary data sources provided by Congruence Engine partners for experimental purposes.


## Investigation methods/ tools/ code/ software


Solara, Reacton, Python


## Outputs

The CG Data Explorer app

## Licence 
This work is licensed under a [Creative Commons Attribution 4.0 License - CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
